apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "llamafactory.fullname" . }}
  labels:
    {{- include "llamafactory.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.replicaCount }}
  # Recreate strategy â€“ GPU workloads should not run two
  # replicas in parallel during rolling updates.
  strategy:
    type: Recreate
  selector:
    matchLabels:
      {{- include "llamafactory.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "llamafactory.selectorLabels" . | nindent 8 }}
        sidecar.istio.io/inject: "true"
    spec:
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- if .Values.hostIPC }}
      hostIPC: true
      {{- end }}
      {{- with .Values.podSecurityContext }}
      securityContext:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      containers:
        - name: {{ .Chart.Name }}
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          {{- if eq .Values.mode "webui" }}
          command: ["llamafactory-cli", "webui"]
          {{- else }}
          command: ["llamafactory-cli", "api"]
          {{- end }}
          ports:
            {{- if eq .Values.mode "webui" }}
            - name: http
              containerPort: {{ .Values.gradio.serverPort }}
              protocol: TCP
            {{- else }}
            - name: http
              containerPort: {{ .Values.api.port }}
              protocol: TCP
            {{- end }}
          env:
            - name: GRADIO_SERVER_NAME
              value: {{ .Values.gradio.serverName | quote }}
            - name: GRADIO_SERVER_PORT
              value: {{ .Values.gradio.serverPort | quote }}
            - name: API_PORT
              value: {{ .Values.api.port | quote }}
            {{- range .Values.extraEnv }}
            - name: {{ .name }}
              value: {{ .value | quote }}
            {{- end }}
            {{- if or .Values.huggingface.token .Values.huggingface.existingSecret }}
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: {{ if .Values.huggingface.existingSecret }}{{ .Values.huggingface.existingSecret }}{{ else }}{{ include "llamafactory.fullname" . }}-hf-token{{ end }}
                  key: {{ .Values.huggingface.existingSecretKey | default "HF_TOKEN" }}
            {{- end }}
          resources:
            {{- toYaml .Values.resources | nindent 12 }}
          volumeMounts:
            # Shared memory for PyTorch / NCCL
            - name: dshm
              mountPath: /dev/shm
            - name: hf-cache
              mountPath: {{ .Values.persistence.hfCache.mountPath }}
            - name: data
              mountPath: {{ .Values.persistence.data.mountPath }}
            - name: output
              mountPath: {{ .Values.persistence.output.mountPath }}
          {{- with .Values.securityContext }}
          securityContext:
            {{- toYaml . | nindent 12 }}
          {{- end }}
          # Gradio / API can take time to initialise on first model load
          startupProbe:
            httpGet:
              path: /
              port: http
            failureThreshold: 60
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /
              port: http
            periodSeconds: 30
            timeoutSeconds: 5
          readinessProbe:
            httpGet:
              path: /
              port: http
            periodSeconds: 10
            timeoutSeconds: 5
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: {{ .Values.shmSizeGi }}Gi
        {{- if .Values.persistence.hfCache.enabled }}
        - name: hf-cache
          persistentVolumeClaim:
            claimName: {{ include "llamafactory.fullname" . }}-hf-cache
        {{- else }}
        - name: hf-cache
          emptyDir: {}
        {{- end }}
        {{- if .Values.persistence.data.enabled }}
        - name: data
          persistentVolumeClaim:
            claimName: {{ include "llamafactory.fullname" . }}-data
        {{- else }}
        - name: data
          emptyDir: {}
        {{- end }}
        {{- if .Values.persistence.output.enabled }}
        - name: output
          persistentVolumeClaim:
            claimName: {{ include "llamafactory.fullname" . }}-output
        {{- else }}
        - name: output
          emptyDir: {}
        {{- end }}
